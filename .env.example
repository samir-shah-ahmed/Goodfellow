# =========================
# Goodfellow - .env.example
# Copy to `.env` and fill in secrets for local/dev.
# In prod, set these as real environment variables (don't commit `.env`).
# =========================

# --- App & Runtime ---
ENV=development            # development | staging | production
RELEASE=local              # git sha / version tag for tracing
PORT=8000                  # uvicorn port

# --- Logging ---
LOG_LEVEL=INFO             # DEBUG | INFO | WARNING | ERROR
LOG_FORMAT=plain           # plain | json
REQUEST_LOG_SAMPLE=1.0     # 0.0â€“1.0 (fraction of requests to log at info)

# --- CORS / Frontend ---
# Comma-separated origins; include your frontend(s)
ALLOWED_ORIGINS=http://localhost:3000,http://127.0.0.1:3000

# --- Database (Postgres recommended) ---
# Prefer DATABASE_URL; parts below are fallback to compose it.
DATABASE_URL=              # e.g. postgresql+psycopg://postgres:postgres@localhost:5432/balanced_alpha
DB_HOST=localhost
DB_PORT=5432
DB_NAME=balanced_alpha
DB_USER=postgres
DB_PASSWORD=postgres

# (Optional) SQLite for quick local spikes (override DATABASE_URL if used)
# SQLITE_PATH=./var/balanced_alpha.db
# DATABASE_URL=sqlite+aiosqlite:///./var/balanced_alpha.db

# --- Redis / Queue (for ingestion workers, caching, rate limits) ---
REDIS_URL=redis://localhost:6379/0

# --- Providers / Data Sources ---
# News, RSS, other providers. Comment out ones you don't use yet.
NEWSAPI_KEY=your_newsapi_key
# TWITTER_BEARER=...
# NYT_API_KEY=...
# GUARDIAN_API_KEY=...

# --- AI / LLMs ---
LLM_PROVIDER=openai        # openai | azureopenai | anthropic | vertex | stub
OPENAI_API_KEY=            # if LLM_PROVIDER=openai
AZURE_OPENAI_API_KEY=      # if LLM_PROVIDER=azureopenai
AZURE_OPENAI_ENDPOINT=
ANTHROPIC_API_KEY=

MODEL_NAME=gpt-4o-mini     # default classification/summarization model
LLM_TEMPERATURE=0.0
LLM_MAX_TOKENS=1000

# --- Embeddings / Semantic Search (optional now, future-ready) ---
USE_EMBEDDINGS=false       # true | false
EMBEDDING_MODEL=text-embedding-3-small
# If using pgvector:
USE_PGVECTOR=false         # true | false

# --- Ingestion Behavior ---
DEFAULT_PAGE_SIZE=50
FETCH_TIMEOUT_SECS=15
USER_AGENT=BalancedAlpha/0.1 (+https://example.com)
MAX_CONCURRENT_FETCHES=10  # per worker (tune with care)

# --- Classification Thresholds ---
CONFIDENCE_ATTACH=0.6      # link ticker/topic if >= this score
CONFIDENCE_WEAK=0.4        # record as weak signal if >= this score
ONLY_CALL_LLM_WHEN_AMBIGUOUS=true  # gate LLM usage for cost control

# --- API & Auth (enable when you expose public endpoints) ---
ENABLE_API_KEYS=false      # true | false
API_KEY_HEADER=X-API-Key
JWT_SECRET=change-me       # only if you later use JWT auth
JWT_EXPIRES_MIN=60

# --- Rate Limiting (only active if ENABLE_API_KEYS=true or middleware enabled) ---
RATE_LIMIT_WINDOW_SEC=60
RATE_LIMIT_MAX_REQUESTS=120

# --- Observability ---
SENTRY_DSN=                # optional: set in staging/prod
OTEL_EXPORTER_OTLP_ENDPOINT=   # optional OpenTelemetry collector
ENABLE_PROMETHEUS_METRICS=true

# --- Features / Flags ---
FEATURE_ADMIN_ENDPOINTS=true       # internal CRUD for tickers/topics/aliases
FEATURE_STORE_FULLTEXT=true        # set false to store only excerpts for compliance
FEATURE_CURSOR_PAGINATION=true

# --- Security / Compliance ---
# Domains where only excerpts are allowed (comma-separated), e.g., medium.com, ft.com
EXCERPT_ONLY_DOMAINS=
# Max chars to persist when excerpt-only is active
EXCERPT_MAX_CHARS=1200

# --- Frontend Build/URLs (for integration/testing) ---
FRONTEND_URL=http://localhost:3000
PUBLIC_BASE_URL=http://localhost:8000

# --- Email / Notifications (future) ---
SMTP_HOST=
SMTP_PORT=587
SMTP_USER=
SMTP_PASSWORD=
SMTP_FROM="Balanced Alpha <no-reply@balancedalpha.local>"

# --- Misc. Paths ---
DATA_DIR=./var
LOG_DIR=./var/logs
